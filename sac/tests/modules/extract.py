import os
import pandas as pd
import shutil
from tensorboard.backend.event_processing.event_accumulator import EventAccumulator

taskname = "reacher"

tasknames = ['ant', 'humanoid', 'lunar', 'pendulum', 'reacher', 'hopper', 'walker']

def extract_tensorboard_logs_by_folder(log_root_dir, output_root_folder="tensorboard_extracted_logs", output_csv=True):
    """
    ê° TensorBoard ë¡œê·¸ í´ë”ë³„ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ì €ì¥.
    :param log_root_dir: TensorBoard ë¡œê·¸ì˜ ìµœìƒìœ„ í´ë” (ì—¬ëŸ¬ ê°œì˜ ì‹¤í—˜ í´ë”ê°€ í¬í•¨ë¨)
    :param output_root_folder: ë¡œê·¸ ë°ì´í„°ë¥¼ ì €ì¥í•  í´ë”
    :param output_csv: CSV ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    :return: ëª¨ë“  ë°ì´í„°ë¥¼ í¬í•¨í•œ Pandas DataFrame
    """
    if not os.path.isdir(log_root_dir):
        return

    all_global_data = []  # ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    os.makedirs(output_root_folder, exist_ok=True)  # âœ… ìµœìƒìœ„ ì €ì¥ í´ë” ìƒì„±

    # âœ… ìµœìƒìœ„ í´ë” ë‚´ ê° ì‹¤í—˜ í´ë” íƒìƒ‰
    for experiment_folder in os.listdir(log_root_dir):
        experiment_path = os.path.join(log_root_dir, experiment_folder)
        if not os.path.isdir(experiment_path):  # ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
            continue
        
        print(f"ğŸ” ì²˜ë¦¬ ì¤‘: {experiment_folder}")
        experiment_output_folder = os.path.join(output_root_folder, experiment_folder)
        # os.makedirs(experiment_output_folder, exist_ok=True)  # âœ… ì‹¤í—˜ë³„ ì €ì¥ í´ë” ìƒì„±

        # âœ… í•´ë‹¹ í´ë” ë‚´ ëª¨ë“  TensorBoard ë¡œê·¸ íŒŒì¼ íƒìƒ‰
        log_files = []
        for root, _, files in os.walk(experiment_path):
            for file in files:
                if "tfevents" in file:
                    log_files.append(os.path.join(root, file))

        print(f"ğŸ“‚ ë°œê²¬ëœ TensorBoard ë¡œê·¸ íŒŒì¼ ({experiment_folder}): {len(log_files)}ê°œ")

        # âœ… ëª¨ë“  ë¡œê·¸ íŒŒì¼ ì²˜ë¦¬
        subnum = 0
        for event_path in log_files:
            all_experiment_data = []  # í˜„ì¬ í´ë” ë‚´ ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            experiment_output_folder_sub = f"{experiment_output_folder}_{subnum}"
            os.makedirs(experiment_output_folder_sub, exist_ok=True)
            subnum += 1
            print(f"ğŸ“‚ ì²˜ë¦¬ ì¤‘: {event_path}")
            event_acc = EventAccumulator(event_path)
            event_acc.Reload()

            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
            tags = event_acc.Tags()["scalars"]
            print(f"âœ… {len(tags)}ê°œ íƒœê·¸ ë°œê²¬: {tags}")

            # ê° íƒœê·¸ë³„ ë°ì´í„° ì¶”ì¶œ
            for tag in tags:
                scalars = event_acc.Scalars(tag)
                df = pd.DataFrame([(s.step, s.value) for s in scalars], columns=["Step", "Value"])
                df["Tag"] = tag
                df["Source"] = os.path.basename(event_path)  # íŒŒì¼ ê²½ë¡œ ëŒ€ì‹  íŒŒì¼ ì´ë¦„ë§Œ ì €ì¥
                all_experiment_data.append(df)

                # âœ… ì‹¤í—˜ë³„ íƒœê·¸ ë°ì´í„° ì €ì¥ (Append ëª¨ë“œ)
                tag_filename = f"{experiment_output_folder_sub}/log_data_{tag.replace('/', '_')}.csv"
                if output_csv:
                    if os.path.exists(tag_filename):
                        df.to_csv(tag_filename, mode="a", header=False, index=False)
                    else:
                        df.to_csv(tag_filename, index=False)

            # âœ… ì‹¤í—˜ë³„ ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ CSVë¡œ ì €ì¥
            if all_experiment_data:
                final_experiment_df = pd.concat(all_experiment_data, ignore_index=True).drop_duplicates()
                all_global_data.append(final_experiment_df)  # ê¸€ë¡œë²Œ ë°ì´í„°ì— ì¶”ê°€
                experiment_csv_path = os.path.join(experiment_output_folder_sub, "all_tensorboard_data.csv")

                if output_csv:
                    final_experiment_df.to_csv(experiment_csv_path, index=False)
                    print(f"âœ… {experiment_folder}ì˜ ëª¨ë“  ë°ì´í„°ê°€ {experiment_csv_path}ë¡œ ì €ì¥ë¨")

    # âœ… ëª¨ë“  ì‹¤í—˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ CSVë¡œ ì €ì¥
    if all_global_data:
        final_global_df = pd.concat(all_global_data, ignore_index=True).drop_duplicates()
        global_csv_path = os.path.join(output_root_folder, "global_tensorboard_data.csv")

        if output_csv:
            final_global_df.to_csv(global_csv_path, index=False)
            print(f"âœ… ëª¨ë“  ì‹¤í—˜ì˜ ë°ì´í„°ë¥¼ {global_csv_path}ë¡œ ì €ì¥ë¨")

    return final_global_df


def extract_files(taskname, rootdir = ""):
    # âœ… ì‹¤í–‰ ì½”ë“œ
    log_root_directory = f"{rootdir}tensorboard_logs/{taskname}"  # ğŸš€ ìµœìƒìœ„ TensorBoard ë¡œê·¸ í´ë” ê²½ë¡œ ì…ë ¥
    output_dir = f"{rootdir}temp_logs/tensorboard_extracted_logs_{taskname}"
    df = extract_tensorboard_logs_by_folder(log_root_directory, output_dir)

def extract_second_column_from_csv(input_folder, filtered_folder, allist=["Lips_SAC_", "Vanilla_", "CAPS_SAC_", "DA_SAC_", "L2C2_SAC_"]):
    if not os.path.exists(input_folder):
        print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {input_folder}")
        return
    
    os.makedirs(filtered_folder, exist_ok=True)
    
    find_csv_list = ["log_data_rollout_ep_rew_mean.csv", "log_data_train_oscillation.csv"]
    dtframes = {}
    for csv_name in find_csv_list:
        dtframes[csv_name] = pd.DataFrame()
    for alname in allist:
        column_dict = {}
        for csv_name in find_csv_list:
            column_dict[csv_name] = []
        for dirname in os.listdir(input_folder):
            dirpath = os.path.join(input_folder, dirname)
            if not os.path.isdir(dirpath):  # ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
                continue
            if not dirname.startswith(alname):
                continue
            for filename in os.listdir(dirpath):
                if filename in find_csv_list:
                    filepath = os.path.join(dirpath,filename)
                    try:
                        # CSV íŒŒì¼ ì½ê¸°
                        df = pd.read_csv(filepath)

                        # ë‘ ë²ˆì§¸ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                        if df.shape[1] < 2:
                            print(f"âš ï¸ {filename}: ë‘ ë²ˆì§¸ ì—´ì´ ì—†ìŒ, ê±´ë„ˆëœ€.")
                            continue

                        # ë‘ ë²ˆì§¸ ì—´ë§Œ ì¶”ì¶œ
                        second_column_df = df.iloc[:, [1]]
                        
                        column_dict[filename].append(second_column_df)

                    except Exception as e:
                        print(f"âŒ {filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # print(column_dict)
        try:
            for csv_name in find_csv_list:
                series_list = column_dict[csv_name]
                if not series_list:
                    print(f"âš ï¸ {alname} ì— {csv_name} ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìŒ, ê±´ë„ˆëœ€.")
                    continue
                
                    # ê° ì‹¤í–‰ë§ˆë‹¤ ë§ˆì§€ë§‰ í–‰ ê°’ë§Œ ë½‘ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ
                last_values = [s.iloc[-1] for s in series_list]
                last_avg    = float(pd.Series(last_values).mean())

                # ê²°ê³¼ DataFrame ì— column ì¶”ê°€ (í•œ í–‰ì§œë¦¬)
                dtframes[csv_name].loc[0, alname] = last_avg

        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    for csv_name in find_csv_list:
        new_filepath = os.path.join(filtered_folder, csv_name)
        dtframes[csv_name].to_csv(new_filepath, index=False)


def extract_csv(taskname, rootdir = "", allist=["Lips_SAC_", "Vanilla_", "CAPS_SAC_", "DA_SAC_", "L2C2_SAC_"]):
    csv_folder_path = f"{rootdir}temp_logs/tensorboard_extracted_logs_{taskname}" 
    filtered_folder_path = f"{rootdir}filtered/filtered_{taskname}"
    extract_second_column_from_csv(csv_folder_path, filtered_folder_path, allist)


def extract_all(rootdir = "", allist=["Lips_SAC_", "Vanilla_", "CAPS_SAC_", "DA_SAC_", "L2C2_SAC_"]):
    for t in tasknames:
        extract_files(t, rootdir)

    for t in tasknames:
        extract_csv(t, rootdir, allist)
    
    temp_dir = f"{rootdir}temp_logs/"
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)